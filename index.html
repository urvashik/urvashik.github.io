<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Urvashi Khandelwal Stanford Homepage</title>
  
  <meta name="author" content="Urvashi Khandelwal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="images/nlp-logo.jpeg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Urvashi Khandelwal</name>
              </p>
              <p> 
              I am a final year PhD student in Computer Science at Stanford University. I work with the <a href=https://nlp.stanford.edu/>Stanford Natural Language Processing Group</a>, where I am advised by <a href=https://web.stanford.edu/~jurafsky/>Professor Dan Jurafsky</a>.</br>             
              </p>
              <p>
               I work at the intersection of natural language processing and machine learning. More specifically, I am interested in building natural language processing systems that adapt to new tasks and changing data distributions, in an interpretable and fair manner. 
              </p>
              <p style="text-align:left">
                Email: urvashik@stanford.edu</br> 
                <a href="https://twitter.com/ukhndlwl">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/urvashik">Github</a>  &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=2ITGSdgAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="pdfs/resume.pdf">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/urvashik.jpg" >
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Recent News</heading>
				      <ul>
                <li>
                  I won a <a href=https://www.microsoft.com/en-us/research/academic-program/dissertation-grant/#!grant-recipients>Microsoft Research Dissertation Grant</a>, thanks MSR!
                </li>
                <li>
                  I presented our work on Nearest Neighbor Language Models at (virtual) ICLR 2020! Check out my <a href=https://iclr.cc/virtual_2020/poster_HklBjCEKvH.html>talk</a>!
                </li>
                <li>
                  I was the head TA for the Winter 2020 offering of <a href=http://web.stanford.edu/class/cs124/>CS124: From Languages to Information</a>, taught by Prof. Dan Jurafsky at Stanford!
                </li>
								<li>
                  I was invited to speak at the <a href=https://nlp.berkeley.edu/2019/11/12/nov-18-urvashi-khandelwal-john-hewitt/>Berkeley NLP Seminar</a> about my work on Nearest Neighbor Language Models!</br>
                </li>
                <li>
                  Our paper, "<a href=https://nlp.stanford.edu/pubs/clark2019what.pdf>What does BERT look at? An Analysis of BERT's Attention</a>", won the best paper award at BlackboxNLP 2019!
                </li>
                <li>
                  I co-organized the <a href=http://neuralgen.io/>Workshop on Methods for Optimizing and Evaluating Neural Language Generation (NeuralGen 2019)</a> co-located with NAACL'19 in Minneapolis!
                </li>

                <li>
                  I was invited to speak at the <a href=https://www.meetup.com/Bay-Area-Research-in-NLP-and-ML/events/259348080/>Bay Area Research in NLP and ML</a> Meetup in March, 2019!</br>[<a href=pdfs/meetup_march19.pdf>slides</a>]
                </li>
                <li>
                  In Winter 2019, I participated in a policy lab offered by the Stanford Law School called <i>Administering by Algorithm: Artificial Intelligence in the Regulatory State</i>. I was quoted in a <a href=https://news.stanford.edu/2019/02/28/policy-lab-explores-government-administers-algorithm/>Stanford News Service article</a> about it!

                </li>

				      </ul>

            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
				      <ul>
        	      <li>
                  <p>
                    <b><a href=https://arxiv.org/pdf/2010.00710.pdf>Nearest Neighbor Machine Translation.</a></b></br>
                    <b><u>Urvashi Khandelwal</u></b>, Angela Fan, Dan Jurafsky, Luke Zettlemoyer and Mike Lewis.</br>
                     International Conference on Learning Representations (ICLR), 2021.</br> 
                     [<a href=bibs/khandelwal2020nearest.bib>bib</a>][<a href=pdfs/knnmt_iclr.pdf>slides</a>]
                  </p>
         	      </li>


                        <li>
                        <p>
                            <b><a href=https://arxiv.org/pdf/2010.06595.pdf>With Little Power Comes Great Responsibility.</a></b></br>
                            Dallas Card, Peter Henderson, <b><u>Urvashi Khandelwal</u></b>, Robin Jia, Kyle Mahowald and Dan Jurafsky.<br>
                            Empirical Methods in Natural Language Processing (EMNLP), 2020.</br>
                            [<a href=bibs/card2020with.bib>bib</a>]
                        </p>
                        </li>

								<li>
                                <p>
                  <b><a href=https://www.pnas.org/content/pnas/early/2020/06/02/1907367117.full.pdf>Emergent Linguistic Structure in Artificial Neural
                    Networks Trained by Self-Supervision.</a></b></br>
                  Christopher D. Manning, Kevin Clark, John Hewitt, <b><u>Urvashi Khandelwal</u></b> and Omer Levy.</br>
                  Proceedings of the National Academy of Sciences (PNAS), 2020.</br>
                  [<a href=bibs/manning2020emergent.bib>bib</a>]
                  </p>
								</li>

        	      <li>
                  <p>
                    <b><a href=https://openreview.net/pdf?id=HklBjCEKvH>Generalization through Memorization: Nearest Neighbor Language Models.</a></b></br>
                    <b><u>Urvashi Khandelwal</u></b>, Omer Levy, Dan Jurafsky, Luke Zettlemoyer and Mike Lewis.</br>
                    International Conference on Learning Representations (ICLR), 2020.</br> 
                    [<a href=bibs/khandelwal2020generalization.bib>bib</a>][<a href=https://github.com/urvashik/knnlm>code</a>][<a href=pdfs/knnlm_iclr_final.pdf>slides</a>][<a href=https://iclr.cc/virtual_2020/poster_HklBjCEKvH.html>talk</a>]
                  </p>
         	      </li>
                

								<li>
                	<p>
                		<b><a href=https://nlp.stanford.edu/pubs/clark2019what.pdf>What does BERT look at? An Analysis of BERT's Attention.</a></b></br>
                    Kevin Clark, <b><u>Urvashi Khandelwal</u></b>, Omer Levy and Christopher D. Manning.</br>
                    BlackboxNLP@ACL, 2019.</br> 
                    <b style="color:#BC3C3C">Best Paper Award.</b></br>
                    [<a href=bibs/clark2019what.bib>bib</a>]
                	</p>
                </li>


                <li>
                	<p>
                		<b><a href=https://nlp.stanford.edu/pubs/clark2019bam.pdf>BAM! Born-Again Multi-Task Networks for Natural Language Understanding.</a></b></br>
                    Kevin Clark, Minh-Thang Luong, <b><u>Urvashi Khandelwal</u></b>, Christopher D. Manning and Quoc V. Le.</br>
                    Association for Computational Linguistics (ACL), 2019.</br>
                    [<a href=bibs/clark2019bam.bib>bib</a>]
                	</p>
                </li>

								<li>
                	<p>
                    <b><a href=https://arxiv.org/pdf/1905.08836.pdf>Sample Efficient Text Summarization Using a Single Pre-Trained Transformer.</a></b></br>
                    <b><u>Urvashi Khandelwal</u></b>, Kevin Clark, Dan Jurafsky, Lukasz Kaiser.</br>
                    ArXiv Preprint, 2019. Presented at WeCNLP 2019.</br>
                    [<a href=bibs/khandelwal2019sample.bib>bib</a>][<a href=https://github.com/tensorflow/tensor2tensor>code</a>][<a href=pdfs/wecnlp_poster_final.pdf>poster</a>]
                	</p>
                </li>

								<li>
                	<p>
                    <b><a href=https://arxiv.org/pdf/1805.04623.pdf>Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context.</a></b></br>
                    <b><u>Urvashi Khandelwal</u></b>, He He, Peng Qi, Dan Jurafsky.</br>
                    Association for Computational Linguistics (ACL), 2018.</br>
                    [<a href=bibs/khandelwal2018sharp.bib>bib</a>][<a href=https://github.com/urvashik/lm-context-analysis>code</a>][<a href=pdfs/acl2018_poster_final.pdf>poster</a>]
                	</p>
                </li>

								<li>
                  <p>
                    <b><a href=http://hanj.cs.illinois.edu/pdf/kdd14_xren.pdf>ClusCite: Effective Citation Recommendation by Information Network-Based Clustering.</a></b></br>
                    Xiang Ren, Jialu Liu, Xiao Yu, <b><u>Urvashi Khandelwal</u></b>, Quanquan Gu, Lidan. Wang, Jiawei Han.</br>
                    ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2014.
                  </p>
                </li>

                <li>
                  <p>
                    <b><a href=http://hanj.cs.illinois.edu/pdf/wsdm14_xyu.pdf>Personalized Entity Recommendation: A Heterogeneous Information Network Approach.</a></b></br>
                    Xiao Yu, Xiang Ren, Yizhou Sun, Quanquan Gu, Brad Sturt, <b><u>Urvashi Khandelwal</u></b>, Brandon Norick, Jiawei Han.<br>
                    International Conference on Web Search and Data Mining (WSDM), 2014.
                  </p>
                </li>

                <li>
                  <p>
                    <b><a href=http://hanj.cs.illinois.edu/pdf/recsys13_xyu.pdf>HeteRec: Entity Recommendation in Heterogeneous Information Networks with Implicit User Feedback.</a></b></br>
                    Xiao Yu, Xiang Ren, Yizhou Sun, Brad Sturt, <b><u>Urvashi Khandelwal</u></b>, Quanquan Gu, Brandon Norick, Jiawei Han.<br>
                    ACM Conference on Recommender Systems (RecSys), 2013.
                  </p>
                </li>

				      </ul>

            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p style="text-align:left;font-size:small;">
                This website template is from <a href=https://jonbarron.info/ style="text-align:right;font-size:small;">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>


      </td>
    </tr>
  </table>
</body>

</html>
